{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - Google Colab ç‰ˆæœ¬\n",
        "\n",
        "è¿™ä¸ªnotebookæ¼”ç¤ºäº†å¦‚ä½•åœ¨Google Colabä¸­è¿è¡Œè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿï¼Œä½¿ç”¨æœ¬åœ°LLMè¿›è¡Œé¢„æµ‹åˆ†æã€‚\n",
        "\n",
        "## ğŸ¯ åŠŸèƒ½ç‰¹æ€§\n",
        "- å®æ—¶è‚¡ç¥¨æ•°æ®è·å–\n",
        "- æŠ€æœ¯æŒ‡æ ‡è®¡ç®—\n",
        "- AIé©±åŠ¨çš„è‚¡ç¥¨é¢„æµ‹\n",
        "- æœ¬åœ°LLMåˆ†æï¼ˆæ— éœ€APIå¯†é’¥ï¼‰\n",
        "- äº¤äº’å¼Webç•Œé¢\n",
        "\n",
        "## ğŸ“‹ ä½¿ç”¨æ­¥éª¤\n",
        "1. è¿è¡Œç¬¬ä¸€ä¸ªcellå®‰è£…ä¾èµ–\n",
        "2. è¿è¡Œç¬¬äºŒä¸ªcellå¯åŠ¨æœåŠ¡\n",
        "3. è®¿é—®Webç•Œé¢è¿›è¡Œè‚¡ç¥¨é¢„æµ‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ æ­¥éª¤1: å®‰è£…ä¾èµ–å’Œè®¾ç½®ç¯å¢ƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£…ç³»ç»Ÿä¾èµ–\n",
        "!apt-get update\n",
        "!apt-get install -y curl wget\n",
        "\n",
        "# å®‰è£…Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "print(\"âœ… ç³»ç»Ÿä¾èµ–å®‰è£…å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£…Pythonä¾èµ–\n",
        "!pip install -q fastapi uvicorn langgraph langchain langchain-openai yfinance pandas numpy ta pydantic python-multipart python-dotenv httpx aiofiles pyarrow alpha-vantage requests aiohttp ollama jupyter-dash plotly dash\n",
        "\n",
        "print(\"âœ… Pythonä¾èµ–å®‰è£…å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯åŠ¨OllamaæœåŠ¡\n",
        "import subprocess\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def start_ollama():\n",
        "    subprocess.run(['ollama', 'serve'], check=True)\n",
        "\n",
        "# åœ¨åå°å¯åŠ¨Ollama\n",
        "ollama_thread = threading.Thread(target=start_ollama, daemon=True)\n",
        "ollama_thread.start()\n",
        "\n",
        "# ç­‰å¾…æœåŠ¡å¯åŠ¨\n",
        "time.sleep(10)\n",
        "print(\"âœ… OllamaæœåŠ¡å·²å¯åŠ¨\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¸‹è½½LLMæ¨¡å‹\n",
        "!ollama pull qwen2.5:7b\n",
        "\n",
        "# éªŒè¯æ¨¡å‹\n",
        "!ollama list\n",
        "\n",
        "print(\"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
        "import os\n",
        "\n",
        "os.environ[\"LLM_TYPE\"] = \"ollama\"\n",
        "os.environ[\"OLLAMA_MODEL\"] = \"qwen2.5:7b\"\n",
        "os.environ[\"HOST\"] = \"0.0.0.0\"\n",
        "os.environ[\"PORT\"] = \"8000\"\n",
        "os.environ[\"CACHE_TTL_HOURS\"] = \"24\"\n",
        "\n",
        "print(\"âœ… ç¯å¢ƒå˜é‡å·²é…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•Ollamaè¿æ¥\n",
        "import ollama\n",
        "\n",
        "try:\n",
        "    response = ollama.chat(\n",
        "        model=\"qwen2.5:7b\",\n",
        "        messages=[{'role': 'user', 'content': 'Hello, are you working?'}]\n",
        "    )\n",
        "    print(\"âœ… Ollamaæµ‹è¯•æˆåŠŸ\")\n",
        "    print(f\"å›å¤: {response['message']['content']}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Ollamaæµ‹è¯•å¤±è´¥: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ æ­¥éª¤2: ä¸Šä¼ é¡¹ç›®æ–‡ä»¶\n",
        "\n",
        "è¯·ä½¿ç”¨å·¦ä¾§çš„æ–‡ä»¶é¢æ¿ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶åˆ°Colabï¼š\n",
        "- `backend/` æ–‡ä»¶å¤¹ï¼ˆåŒ…å«æ‰€æœ‰Pythonä»£ç ï¼‰\n",
        "- `frontend/` æ–‡ä»¶å¤¹ï¼ˆåŒ…å«å‰ç«¯ä»£ç ï¼‰\n",
        "\n",
        "æˆ–è€…ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»GitHubå…‹éš†é¡¹ç›®ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä»GitHubå…‹éš†é¡¹ç›®ï¼ˆæ›¿æ¢ä¸ºä½ çš„ä»“åº“åœ°å€ï¼‰\n",
        "# !git clone https://github.com/your-username/stock-predictor.git\n",
        "# %cd stock-predictor\n",
        "\n",
        "print(\"ğŸ“ è¯·ä¸Šä¼ é¡¹ç›®æ–‡ä»¶æˆ–å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„å‘½ä»¤æ¥å…‹éš†é¡¹ç›®\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ æ­¥éª¤3: å¯åŠ¨åº”ç”¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯åŠ¨FastAPIåº”ç”¨\n",
        "import uvicorn\n",
        "from backend.app import app\n",
        "\n",
        "print(\"ğŸš€ å¯åŠ¨è‚¡ç¥¨é¢„æµ‹åº”ç”¨...\")\n",
        "print(\"ğŸ“± åº”ç”¨å°†åœ¨ http://localhost:8000 å¯åŠ¨\")\n",
        "print(\"ğŸ“Š APIæ–‡æ¡£: http://localhost:8000/docs\")\n",
        "print(\"\\næŒ‰ Ctrl+C åœæ­¢åº”ç”¨\")\n",
        "\n",
        "# å¯åŠ¨æœåŠ¡å™¨\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª æ­¥éª¤4: æµ‹è¯•API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•APIç«¯ç‚¹\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# æµ‹è¯•å¥åº·æ£€æŸ¥\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8000/health\")\n",
        "    print(\"âœ… å¥åº·æ£€æŸ¥:\", response.json())\n",
        "except Exception as e:\n",
        "    print(f\"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•è‚¡ç¥¨é¢„æµ‹\n",
        "try:\n",
        "    prediction_data = {\n",
        "        \"symbol\": \"AAPL\",\n",
        "        \"timeframe\": \"1d\"\n",
        "    }\n",
        "    \n",
        "    response = requests.post(\n",
        "        \"http://localhost:8000/predict\",\n",
        "        json=prediction_data\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"âœ… è‚¡ç¥¨é¢„æµ‹æˆåŠŸ:\")\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print(f\"âŒ é¢„æµ‹å¤±è´¥: {response.status_code}\")\n",
        "        print(response.text)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ é¢„æµ‹è¯·æ±‚å¤±è´¥: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ æ³¨æ„äº‹é¡¹\n",
        "\n",
        "1. **ä¼šè¯æ—¶é—´é™åˆ¶**: Colabä¼šè¯æœ‰12å°æ—¶é™åˆ¶\n",
        "2. **å†…å­˜ä½¿ç”¨**: ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œé¿å…è¶…å‡ºé™åˆ¶\n",
        "3. **æ•°æ®æŒä¹…åŒ–**: é‡è¦æ•°æ®è¯·ä¿å­˜åˆ°Google Drive\n",
        "4. **æ¨¡å‹å¤§å°**: Qwen2.5:7bæ¨¡å‹çº¦4.7GBï¼Œç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´\n",
        "5. **ç½‘ç»œè®¿é—®**: ç¡®ä¿å¯ä»¥è®¿é—®å¤–éƒ¨APIè·å–è‚¡ç¥¨æ•°æ®\n",
        "\n",
        "## ğŸ‰ å®Œæˆï¼\n",
        "\n",
        "ç°åœ¨ä½ å¯ä»¥åœ¨Colabä¸­è¿è¡Œè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿäº†ï¼\n",
        "\n",
        "### è®¿é—®æ–¹å¼ï¼š\n",
        "- **APIæ–‡æ¡£**: http://localhost:8000/docs\n",
        "- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health\n",
        "- **è‚¡ç¥¨é¢„æµ‹**: POST http://localhost:8000/predict\n",
        "\n",
        "### ä½¿ç”¨ç¤ºä¾‹ï¼š\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# é¢„æµ‹AAPLè‚¡ç¥¨\n",
        "response = requests.post(\"http://localhost:8000/predict\", \n",
        "                        json={\"symbol\": \"AAPL\", \"timeframe\": \"1d\"})\n",
        "result = response.json()\n",
        "print(result)\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
