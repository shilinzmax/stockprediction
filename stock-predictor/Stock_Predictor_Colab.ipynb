{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 股票预测系统 - Google Colab 版本\n",
        "\n",
        "这个notebook演示了如何在Google Colab中运行股票预测系统，使用本地LLM进行预测分析。\n",
        "\n",
        "## 🎯 功能特性\n",
        "- 实时股票数据获取\n",
        "- 技术指标计算\n",
        "- AI驱动的股票预测\n",
        "- 本地LLM分析（无需API密钥）\n",
        "- 交互式Web界面\n",
        "\n",
        "## 📋 使用步骤\n",
        "1. 运行第一个cell安装依赖\n",
        "2. 运行第二个cell启动服务\n",
        "3. 访问Web界面进行股票预测\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 步骤1: 安装依赖和设置环境\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 安装系统依赖\n",
        "!apt-get update\n",
        "!apt-get install -y curl wget\n",
        "\n",
        "# 安装Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "print(\"✅ 系统依赖安装完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 安装Python依赖\n",
        "!pip install -q fastapi uvicorn langgraph langchain langchain-openai yfinance pandas numpy ta pydantic python-multipart python-dotenv httpx aiofiles pyarrow alpha-vantage requests aiohttp ollama jupyter-dash plotly dash\n",
        "\n",
        "print(\"✅ Python依赖安装完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 启动Ollama服务\n",
        "import subprocess\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def start_ollama():\n",
        "    subprocess.run(['ollama', 'serve'], check=True)\n",
        "\n",
        "# 在后台启动Ollama\n",
        "ollama_thread = threading.Thread(target=start_ollama, daemon=True)\n",
        "ollama_thread.start()\n",
        "\n",
        "# 等待服务启动\n",
        "time.sleep(10)\n",
        "print(\"✅ Ollama服务已启动\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 下载LLM模型\n",
        "!ollama pull qwen2.5:7b\n",
        "\n",
        "# 验证模型\n",
        "!ollama list\n",
        "\n",
        "print(\"✅ 模型下载完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置环境变量\n",
        "import os\n",
        "\n",
        "os.environ[\"LLM_TYPE\"] = \"ollama\"\n",
        "os.environ[\"OLLAMA_MODEL\"] = \"qwen2.5:7b\"\n",
        "os.environ[\"HOST\"] = \"0.0.0.0\"\n",
        "os.environ[\"PORT\"] = \"8000\"\n",
        "os.environ[\"CACHE_TTL_HOURS\"] = \"24\"\n",
        "\n",
        "print(\"✅ 环境变量已配置\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试Ollama连接\n",
        "import ollama\n",
        "\n",
        "try:\n",
        "    response = ollama.chat(\n",
        "        model=\"qwen2.5:7b\",\n",
        "        messages=[{'role': 'user', 'content': 'Hello, are you working?'}]\n",
        "    )\n",
        "    print(\"✅ Ollama测试成功\")\n",
        "    print(f\"回复: {response['message']['content']}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ollama测试失败: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📁 步骤2: 上传项目文件\n",
        "\n",
        "请使用左侧的文件面板上传以下文件到Colab：\n",
        "- `backend/` 文件夹（包含所有Python代码）\n",
        "- `frontend/` 文件夹（包含前端代码）\n",
        "\n",
        "或者使用以下命令从GitHub克隆项目：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从GitHub克隆项目（替换为你的仓库地址）\n",
        "# !git clone https://github.com/your-username/stock-predictor.git\n",
        "# %cd stock-predictor\n",
        "\n",
        "print(\"📁 请上传项目文件或取消注释上面的命令来克隆项目\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 步骤3: 启动应用\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 启动FastAPI应用\n",
        "import uvicorn\n",
        "from backend.app import app\n",
        "\n",
        "print(\"🚀 启动股票预测应用...\")\n",
        "print(\"📱 应用将在 http://localhost:8000 启动\")\n",
        "print(\"📊 API文档: http://localhost:8000/docs\")\n",
        "print(\"\\n按 Ctrl+C 停止应用\")\n",
        "\n",
        "# 启动服务器\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧪 步骤4: 测试API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试API端点\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# 测试健康检查\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8000/health\")\n",
        "    print(\"✅ 健康检查:\", response.json())\n",
        "except Exception as e:\n",
        "    print(f\"❌ 健康检查失败: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试股票预测\n",
        "try:\n",
        "    prediction_data = {\n",
        "        \"symbol\": \"AAPL\",\n",
        "        \"timeframe\": \"1d\"\n",
        "    }\n",
        "    \n",
        "    response = requests.post(\n",
        "        \"http://localhost:8000/predict\",\n",
        "        json=prediction_data\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"✅ 股票预测成功:\")\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print(f\"❌ 预测失败: {response.status_code}\")\n",
        "        print(response.text)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ 预测请求失败: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📝 注意事项\n",
        "\n",
        "1. **会话时间限制**: Colab会话有12小时限制\n",
        "2. **内存使用**: 监控内存使用情况，避免超出限制\n",
        "3. **数据持久化**: 重要数据请保存到Google Drive\n",
        "4. **模型大小**: Qwen2.5:7b模型约4.7GB，确保有足够空间\n",
        "5. **网络访问**: 确保可以访问外部API获取股票数据\n",
        "\n",
        "## 🎉 完成！\n",
        "\n",
        "现在你可以在Colab中运行股票预测系统了！\n",
        "\n",
        "### 访问方式：\n",
        "- **API文档**: http://localhost:8000/docs\n",
        "- **健康检查**: http://localhost:8000/health\n",
        "- **股票预测**: POST http://localhost:8000/predict\n",
        "\n",
        "### 使用示例：\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# 预测AAPL股票\n",
        "response = requests.post(\"http://localhost:8000/predict\", \n",
        "                        json={\"symbol\": \"AAPL\", \"timeframe\": \"1d\"})\n",
        "result = response.json()\n",
        "print(result)\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
