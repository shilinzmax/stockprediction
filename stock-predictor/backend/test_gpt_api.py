#!/usr/bin/env python3
"""
GPT APIæµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•GPTæ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import requests
import json
from core.llm_manager import get_llm_analyzer, get_gpt_status
from core.state import PredictionRequest

def test_gpt_status():
    """æµ‹è¯•GPTçŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥GPTçŠ¶æ€...")
    status = get_gpt_status()
    
    print(f"GPTå¯ç”¨: {status['available']}")
    if status['available']:
        print(f"æ¨¡å‹: {status.get('model', 'Unknown')}")
        print(f"æ¸©åº¦: {status.get('temperature', 'Unknown')}")
        print(f"APIå¯†é’¥å·²é…ç½®: {status.get('api_key_configured', False)}")
    else:
        print(f"åŸå› : {status.get('reason', 'Unknown')}")
    
    return status['available']

def test_llm_analyzer():
    """æµ‹è¯•LLMåˆ†æå™¨"""
    print("\nğŸ§  æµ‹è¯•LLMåˆ†æå™¨...")
    
    try:
        llm_analyzer = get_llm_analyzer()
        
        # æµ‹è¯•ç®€å•çš„åˆ†æ
        test_data = {
            "symbol": "AAPL",
            "current_price": 150.0,
            "indicators": {
                "rsi": 45,
                "macd": 0.5,
                "sma_20": 148.0,
                "sma_50": 145.0
            }
        }
        
        print("å‘é€æµ‹è¯•æ•°æ®åˆ°GPT...")
        result = llm_analyzer.analyze_stock_data(test_data)
        
        if result and not result.get("error"):
            print("âœ… GPTåˆ†ææˆåŠŸ!")
            print(f"æ–¹å‘: {result.get('direction', 'Unknown')}")
            print(f"æ¦‚ç‡: {result.get('probability', 'Unknown')}")
            print(f"æ¨ç†: {result.get('reasoning', 'No reasoning provided')[:100]}...")
            return True
        else:
            print(f"âŒ GPTåˆ†æå¤±è´¥: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ LLMåˆ†æå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

async def test_prediction_pipeline():
    """æµ‹è¯•é¢„æµ‹ç®¡é“"""
    print("\nğŸ”® æµ‹è¯•é¢„æµ‹ç®¡é“...")
    
    try:
        from graph.pipeline import StockPredictionPipeline
        pipeline = StockPredictionPipeline()
        
        # åˆ›å»ºæµ‹è¯•è¯·æ±‚
        request = PredictionRequest(
            symbol="AAPL",
            timeframe="1d"
        )
        
        print("è¿è¡Œé¢„æµ‹ç®¡é“...")
        result = await pipeline.predict(request.symbol, request.timeframe)
        
        if result and not result.get("error"):
            print("âœ… é¢„æµ‹ç®¡é“æˆåŠŸ!")
            print(f"æ–¹å‘: {result.get('direction', 'Unknown')}")
            print(f"æ¦‚ç‡: {result.get('probability', 'Unknown')}")
            print(f"ä»·æ ¼èŒƒå›´: {result.get('price_range', 'Unknown')}")
            return True
        else:
            print(f"âŒ é¢„æµ‹ç®¡é“å¤±è´¥: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ é¢„æµ‹ç®¡é“æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_api_endpoints():
    """æµ‹è¯•APIç«¯ç‚¹"""
    print("\nğŸŒ æµ‹è¯•APIç«¯ç‚¹...")
    
    base_url = "http://localhost:8000"
    
    # æµ‹è¯•GPTçŠ¶æ€ç«¯ç‚¹
    try:
        response = requests.get(f"{base_url}/api/gpt-status", timeout=10)
        if response.status_code == 200:
            data = response.json()
            print("âœ… GPTçŠ¶æ€ç«¯ç‚¹æ­£å¸¸")
            print(f"GPTå¯ç”¨: {data.get('gpt_available', False)}")
            return True
        else:
            print(f"âŒ GPTçŠ¶æ€ç«¯ç‚¹å¤±è´¥: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨: {str(e)}")
        print("è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: python app.py")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹GPT APIæµ‹è¯•...\n")
    
    # æµ‹è¯•1: GPTçŠ¶æ€
    gpt_available = test_gpt_status()
    
    if not gpt_available:
        print("\nâŒ GPTä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®:")
        print("1. ç¡®ä¿åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®äº†OPENAI_API_KEY")
        print("2. ç¡®ä¿APIå¯†é’¥æœ‰æ•ˆä¸”æœ‰ä½™é¢")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return
    
    # æµ‹è¯•2: LLMåˆ†æå™¨
    llm_works = test_llm_analyzer()
    
    # æµ‹è¯•3: é¢„æµ‹ç®¡é“
    pipeline_works = await test_prediction_pipeline()
    
    # æµ‹è¯•4: APIç«¯ç‚¹
    api_works = test_api_endpoints()
    
    # æ€»ç»“
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"GPTçŠ¶æ€: {'âœ…' if gpt_available else 'âŒ'}")
    print(f"LLMåˆ†æå™¨: {'âœ…' if llm_works else 'âŒ'}")
    print(f"é¢„æµ‹ç®¡é“: {'âœ…' if pipeline_works else 'âŒ'}")
    print(f"APIç«¯ç‚¹: {'âœ…' if api_works else 'âŒ'}")
    
    if all([gpt_available, llm_works, pipeline_works, api_works]):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! GPT APIå·¥ä½œæ­£å¸¸!")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ—¥å¿—")

if __name__ == "__main__":
    asyncio.run(main())
